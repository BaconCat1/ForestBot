import { readFileSync } from "fs";
import { writeFile } from "fs/promises";
import { fileURLToPath } from "url";

const BAD_WORDS_FILE_URL = new URL("../../../../json/bad_words.json", import.meta.url);
const BAD_WORDS_FILE_PATH = fileURLToPath(BAD_WORDS_FILE_URL);

const EXPLICIT_SHORT_BAD_WORDS = new Set([
    "fk",
    "wtf",
    "kys",
    "dm",
    "vcl",
    "vl",
    "vkl",
    "stfu",
]);

const AMBIGUOUS_TOKENS = new Set([
    "hell",
    "sex",
    "fan",
    "mc",
    "bc",
    "bs",
    "mf",
    "tg",
    "nazi",
    "idiot",
    "abuser",
    "degenerate",
    "crud",
    "pota",
    "bobo",
    "inutil",
    "kainis",
    "putik",
    "kamina",
    "haram",
]);

const SEVERE_BASE_WORDS = [
    "nigger",
    "nigga",
    "faggot",
    "fuck",
    "bitch",
    "cunt",
    "whore",
    "cock",
    "dick",
    "ass",
    "shit",
];
const SEVERE_FIRST_CHARS = new Set(SEVERE_BASE_WORDS.map((word) => word[0]));

// Chinese character equivalents for slurs - map to English transliterations
const CHINESE_SLUR_MAP: Record<string, string> = {
    "é»‘é¬¼": "nigger",  // "black ghost/devil" - Chinese slur
    "å°¼å“¥": "nigger",  // phonetic approximation
    "é»‘äºº": "black",   // "black person" - less offensive but watch in context
    "å‚»é€¼": "fuck",    // very offensive in Chinese
    "æ“": "fuck",      // profanity
    "å¦ˆçš„": "fuck",    // "damn" literally "mother's"
    "å©Šå­": "bitch",   // bitch/whore
    "å©Š": "bitch",
};

const CENSOR_CACHE_LIMIT = 2048;
const censorCache = new Map<string, string>();

const LEET_CHAR_MAP: Record<string, string> = {
    "0": "o",
    "1": "i",
    "2": "z",
    "3": "e",
    "4": "a",
    "5": "s",
    "6": "g",
    "7": "t",
    "8": "b",
    "9": "g",
    "@": "a",
    "$": "s",
    "!": "i",
    "+": "t",
};

const UNICODE_CONFUSABLES: Record<string, string> = {
    "Ä±": "i",
    "Ä°": "i",
    "Éª": "i",
    "Î¹": "i",
    "Ñ–": "i",
    "Ğ†": "i",
    "â³": "i",
    "áµ¢": "i",
    "â±": "i",
    "Î¿": "o",
    "Ğ¾": "o",
    "Ïƒ": "o",
    "âŠ™": "o",
    "â—¯": "o",
    "â—": "o",
    "â­•": "o",
    "ğŸ”´": "o",
    "âš«": "o",
    "âšª": "o",
    "Î±": "a",
    "Ğ°": "a",
    "âˆ‚": "a",
    "âº": "a",
    "ğŸ…°": "a",
    "Îµ": "e",
    "Ğµ": "e",
    "âˆˆ": "e",
    "Ï…": "u",
    "Ê‹": "u",
    "Õ½": "u",
    "âˆª": "u",
    "ÊŠ": "u",
    "Î¼": "u",
    "Ï„": "t",
    "Ñ‚": "t",
    "âˆ©": "n",
    "Î·": "n",
    "Ğ¿": "n",
    "Îº": "k",
    "Ğº": "k",
    "Ñ…": "x",
    "Ñ": "c",
    "Ñ•": "s",
    "Ñ€": "p",
    "Ñƒ": "y",
    "Ğ²": "b",
    "Ğ¼": "m",
    "êœ±": "s",
    "Ó": "i",
    "â˜…": "a",
    "â˜†": "a",
    "â™¥": "o",
    "â¤": "o",
    "ğŸ’©": "i",
    "ğŸ‘": "i",
    "ğŸ…¸": "i",
    // Fullwidth Latin characters (U+FF01-U+FF5E)
    "ï½": "a", "ï½‚": "b", "ï½ƒ": "c", "ï½„": "d", "ï½…": "e", "ï½†": "f", "ï½‡": "g",
    "ï½ˆ": "h", "ï½‰": "i", "ï½Š": "j", "ï½‹": "k", "ï½Œ": "l", "ï½": "m", "ï½": "n",
    "ï½": "o", "ï½": "p", "ï½‘": "q", "ï½’": "r", "ï½“": "s", "ï½”": "t", "ï½•": "u",
    "ï½–": "v", "ï½—": "w", "ï½˜": "x", "ï½™": "y", "ï½š": "z",
    "ï¼¡": "a", "ï¼¢": "b", "ï¼£": "c", "ï¼¤": "d", "ï¼¥": "e", "ï¼¦": "f", "ï¼§": "g",
    "ï¼¨": "h", "ï¼©": "i", "ï¼ª": "j", "ï¼«": "k", "ï¼¬": "l", "ï¼­": "m", "ï¼®": "n",
    "ï¼¯": "o", "ï¼°": "p", "ï¼±": "q", "ï¼²": "r", "ï¼³": "s", "ï¼´": "t", "ï¼µ": "u",
    "ï¼¶": "v", "ï¼·": "w", "ï¼¸": "x", "ï¼¹": "y", "ï¼º": "z",
    // Mathematical alphanumeric symbols - Bold (U+1D400-U+1D433)
    "ğš": "a", "ğ›": "b", "ğœ": "c", "ğ": "d", "ğ": "e", "ğŸ": "f", "ğ ": "g",
    "ğ¡": "h", "ğ¢": "i", "ğ£": "j", "ğ¤": "k", "ğ¥": "l", "ğ¦": "m", "ğ§": "n",
    "ğ¨": "o", "ğ©": "p", "ğª": "q", "ğ«": "r", "ğ¬": "s", "ğ­": "t", "ğ®": "u",
    "ğ¯": "v", "ğ°": "w", "ğ±": "x", "ğ²": "y", "ğ³": "z",
    "ğ€": "a", "ğ": "b", "ğ‚": "c", "ğƒ": "d", "ğ„": "e", "ğ…": "f", "ğ†": "g",
    "ğ‡": "h", "ğˆ": "i", "ğ‰": "j", "ğŠ": "k", "ğ‹": "l", "ğŒ": "m", "ğ": "n",
    "ğ": "o", "ğ": "p", "ğ": "q", "ğ‘": "r", "ğ’": "s", "ğ“": "t", "ğ”": "u",
    "ğ•": "v", "ğ–": "w", "ğ—": "x", "ğ˜": "y", "ğ™": "z",
    // Mathematical alphanumeric symbols - Italic
    "ğ‘": "a", "ğ‘": "b", "ğ‘": "c", "ğ‘‘": "d", "ğ‘’": "e", "ğ‘“": "f", "ğ‘”": "g",
    "ğ˜©": "h", "ğ‘–": "i", "ğ‘—": "j", "ğ‘˜": "k", "ğ‘™": "l", "ğ‘š": "m", "ğ‘›": "n",
    "ğ‘œ": "o", "ğ‘": "p", "ğ‘": "q", "ğ‘Ÿ": "r", "ğ‘ ": "s", "ğ‘¡": "t", "ğ‘¢": "u",
    "ğ‘£": "v", "ğ‘¤": "w", "ğ‘¥": "x", "ğ‘¦": "y", "ğ‘§": "z",
    // Small caps and phonetic symbols
    "É´": "n", "É¢": "g", "Ê€": "r", "á´€": "a", "Ê™": "b", "á´„": "c", "á´…": "d",
    "á´‡": "e", "êœ°": "f", "Êœ": "h", "á´Š": "j", "á´‹": "k",
    "ÊŸ": "l", "á´": "m", "á´": "o", "á´˜": "p", "á´›": "t", "á´œ": "u", "á´ ": "v", "á´¡": "w", "Ê": "y", "á´¢": "z",
    "É¡": "g",  // Latin small letter script g (U+0261)
    // Subscript letters
    "â‚": "a", "â‚‘": "e", "â‚•": "h", "â±¼": "j", "â‚–": "k", "â‚—": "l",
    "â‚˜": "m", "â‚™": "n", "â‚’": "o", "â‚š": "p", "áµ£": "r", "â‚›": "s", "â‚œ": "t",
    "áµ¤": "u", "áµ¥": "v", "â‚“": "x",
    // Superscript letters
    "áµƒ": "a", "áµ‡": "b", "á¶œ": "c", "áµˆ": "d", "áµ‰": "e", "á¶ ": "f", "áµ": "g",
    "Ê°": "h", "Ê²": "j", "áµ": "k", "Ë¡": "l", "áµ": "m", "â¿": "n",
    "áµ’": "o", "áµ–": "p", "Ê³": "r", "Ë¢": "s", "áµ—": "t", "áµ˜": "u", "áµ›": "v",
    "Ê·": "w", "Ë£": "x", "Ê¸": "y", "á¶»": "z",
    // Upside down characters
    "É": "a", "q": "b", "É”": "c", "p": "d", "Ç": "e", "ÉŸ": "f", "É“": "b",
    "É¥": "h", "á´‰": "i", "É¾": "r", "Ê": "k", "l": "l", "É¯": "m", "u": "n",
    "o": "o", "d": "p", "b": "q", "É¹": "r", "s": "s", "Ê‡": "t", "n": "u",
    "ÊŒ": "v", "Ê": "w", "x": "x", "Ê": "y", "z": "z",
    // Backwards letters (approximations)
    "á´": "n", "Ç«": "q",
    // More Greek confusables
    "Ï¹": "c", "â²¥": "c", "Ï²": "c", "Î‘": "a", "Î’": "b", "Î•": "e", "Î–": "z",
    "Î—": "h", "Î™": "i", "Îš": "k", "Îœ": "m", "Î": "n", "ÎŸ": "o", "Î¡": "p",
    "Î¤": "t", "Î¥": "y", "Î§": "x",
    // Runic characters that look like Latin
    "á›”": "b", "áš±": "r", "á›": "t", "ášº": "h", "áš ": "f", "á›’": "b",
    // Chinese/Japanese numbers and similar
    "å": "t", "ä¸": "t", "ã€‡": "o", "â—‹": "o", "é›¶": "o",
    // Enclosed alphanumerics (U+1F100-U+1F1FF)
    "ğŸ„°": "a", "ğŸ„±": "b", "ğŸ„²": "c", "ğŸ„³": "d", "ğŸ„´": "e", "ğŸ„µ": "f", "ğŸ„¶": "g",
    "ğŸ„·": "h", "ğŸ„¸": "i", "ğŸ„¹": "j", "ğŸ„º": "k", "ğŸ„»": "l", "ğŸ„¼": "m", "ğŸ„½": "n",
    "ğŸ„¾": "o", "ğŸ„¿": "p", "ğŸ…€": "q", "ğŸ…": "r", "ğŸ…‚": "s", "ğŸ…ƒ": "t", "ğŸ…„": "u",
    "ğŸ……": "v", "ğŸ…†": "w", "ğŸ…‡": "x", "ğŸ…ˆ": "y", "ğŸ…‰": "z",
    // Circled letters (uppercase A-Z: U+24B6 to U+24CF)
    "â’¶": "a",
    "â’·": "b",
    "â’¸": "c",
    "â’¹": "d",
    "â’º": "e",
    "â’»": "f",
    "â’¼": "g",
    "â’½": "h",
    "â’¾": "i",
    "â’¿": "j",
    "â“€": "k",
    "â“": "l",
    "â“‚": "m",
    "â“ƒ": "n",
    "â“„": "o",
    "â“…": "p",
    "â“†": "q",
    "â“‡": "r",
    "â“ˆ": "s",
    "â“‰": "t",
    "â“Š": "u",
    "â“‹": "v",
    "â“Œ": "w",
    "â“": "x",
    "â“": "y",
    "â“": "z",
    // Circled letters (lowercase a-z: U+24D0 to U+24E9)
    "â“": "a",
    "â“‘": "b",
    "â“’": "c",
    "â““": "d",
    "â“”": "e",
    "â“•": "f",
    "â“–": "g",
    "â“—": "h",
    "â“˜": "i",
    "â“™": "j",
    "â“š": "k",
    "â“›": "l",
    "â“œ": "m",
    "â“": "n",
    "â“": "o",
    "â“Ÿ": "p",
    "â“ ": "q",
    "â“¡": "r",
    "â“¢": "s",
    "â“£": "t",
    "â“¤": "u",
    "â“¥": "v",
    "â“¦": "w",
    "â“§": "x",
    "â“¨": "y",
    "â“©": "z",
    // Cherokee characters that look like Latin letters (uppercase U+13A0-U+13F5)
    "á ": "d",
    "á¡": "r",
    "á¢": "i",
    "áª": "a",
    "á«": "j",
    "á": "l",
    "á·": "m",
    "á¾": "o",
    "á¢": "p",
    "áš": "s",
    "á†": "t",
    "á™": "v",
    "á³": "w",
    "á½": "y",
    "áƒ": "z",
    // Cherokee small letters (lowercase U+AB70-U+ABBF)
    "ê­°": "d",
    "ê­±": "r",
    "ê­²": "i",
    "ê­º": "a",
    "ê­»": "j",
    "ê®®": "l",
    "ê®‡": "m",
    "ê®": "o",
    "ê®²": "p",
    "ê®ª": "s",
    "ê®–": "t",
    "ê®©": "v",
    "ê®ƒ": "w",
    "ê®": "y",
    "ê®“": "z",
};

let normalizedBadWords: string[] = [];
let BAD_WORD_SET = new Set<string>();
let BAD_WORD_FIRST_CHARS = new Set<string>();
const SEVERE_SUBSTRING_ROOTS = [...new Set([
    "nigger",
    "nigga",
    "faggot",
    "kike",
    "spic",
    "chink",
    "asshole",
    "cock",
    "dick",
    "pussy",
    "cunt",
])];
const FALLBACK_BAD_WORDS = [...new Set([...SEVERE_BASE_WORDS, ...SEVERE_SUBSTRING_ROOTS])];

function warnFilterConfig(message: string): void {
    console.warn(`[warn] - Profanity filter: ${message}`);
}

function normalizeWordForStorage(word: string): string {
    return String(word ?? "").trim().toLowerCase();
}

function persistBadWordsFile(words: string[]): Promise<void> {
    return writeFile(BAD_WORDS_FILE_URL, JSON.stringify({ words }, null, 2));
}

function rebuildLookup(words: string[]): void {
    normalizedBadWords = [...new Set(
        words
            .map(normalizeWordForStorage)
            .filter((word) => word.length > 0)
    )];

    BAD_WORD_SET = new Set(normalizedBadWords);
    BAD_WORD_FIRST_CHARS = new Set(normalizedBadWords.map((word) => word[0]));
    censorCache.clear();
}

function loadBadWordsFromDisk(): void {
    try {
        const raw = readFileSync(BAD_WORDS_FILE_URL, "utf8");
        const parsed = JSON.parse(raw) as { words?: unknown } | unknown;

        if (!parsed || typeof parsed !== "object" || !("words" in parsed)) {
            warnFilterConfig(`"${BAD_WORDS_FILE_PATH}" is missing the "words" field. Using fallback list.`);
            rebuildLookup(FALLBACK_BAD_WORDS);
            return;
        }

        const words = Array.isArray(parsed.words) ? parsed.words.filter((w): w is string => typeof w === "string") : [];
        if (!Array.isArray(parsed.words)) {
            warnFilterConfig(`"${BAD_WORDS_FILE_PATH}" has invalid "words" format. Using fallback list.`);
            rebuildLookup(FALLBACK_BAD_WORDS);
            return;
        }

        if (words.length === 0) {
            warnFilterConfig(`"${BAD_WORDS_FILE_PATH}" loaded with 0 words. Censoring may be weak until words are added.`);
        }

        rebuildLookup(words);
    } catch (error) {
        const reason = error instanceof Error ? error.message : String(error);
        warnFilterConfig(`failed to load "${BAD_WORDS_FILE_PATH}" (${reason}). Using fallback list.`);
        rebuildLookup(FALLBACK_BAD_WORDS);
    }
}

loadBadWordsFromDisk();

function maskWord(word: string): string {
    if (word.length <= 1) return word;
    return `${word[0]}${"*".repeat(word.length - 1)}`;
}

function isAsciiWordChar(charCode: number): boolean {
    return (
        (charCode >= 48 && charCode <= 57) ||
        (charCode >= 65 && charCode <= 90) ||
        (charCode >= 97 && charCode <= 122)
    );
}

function normalizeObfuscatedSegment(segment: string): string {
    let out = "";
    
    for (const char of segment) {
        const codePoint = char.codePointAt(0);
        if (codePoint === undefined) continue;
        
        // Skip zero-width characters
        if (codePoint === 0x200B || // Zero Width Space
            codePoint === 0x200C || // Zero Width Non-Joiner
            codePoint === 0x200D || // Zero Width Joiner
            codePoint === 0xFEFF) { // Zero Width No-Break Space
            continue;
        }
        
        // Skip combining diacritical marks (U+0300-U+036F)
        if (codePoint >= 0x0300 && codePoint <= 0x036F) {
            continue;
        }
        
        // Skip combining marks for symbols (U+20D0-U+20FF)
        if (codePoint >= 0x20D0 && codePoint <= 0x20FF) {
            continue;
        }
        
        const lowered = char.toLowerCase();
        
        if (isAsciiWordChar(codePoint)) {
            out += LEET_CHAR_MAP[lowered] ?? lowered;
            continue;
        }

        const mapped =
            LEET_CHAR_MAP[char] ??
            LEET_CHAR_MAP[lowered] ??
            UNICODE_CONFUSABLES[char] ??
            UNICODE_CONFUSABLES[lowered];
        if (mapped) {
            out += mapped;
        }
    }
    return out;
}

function isWordLikeCharacter(char: string): boolean {
    const codePoint = char.codePointAt(0);
    if (codePoint === undefined) return false;
    if (isAsciiWordChar(codePoint)) return true;

    // Chinese/CJK characters are word-like
    if ((codePoint >= 0x4E00 && codePoint <= 0x9FFF) ||  // CJK Unified Ideographs
        (codePoint >= 0x3400 && codePoint <= 0x4DBF) ||  // CJK Extension A
        (codePoint >= 0x20000 && codePoint <= 0x2A6DF)) { // CJK Extension B
        return true;
    }

    const lowered = char.toLowerCase();
    return (
        char in LEET_CHAR_MAP ||
        lowered in LEET_CHAR_MAP ||
        char in UNICODE_CONFUSABLES ||
        lowered in UNICODE_CONFUSABLES
    );
}

function isBadWordToken(lowerToken: string): boolean {
    if (lowerToken.length === 0) return false;
    if (AMBIGUOUS_TOKENS.has(lowerToken)) return false;
    if (lowerToken.length <= 2 && !EXPLICIT_SHORT_BAD_WORDS.has(lowerToken)) return false;
    if (!BAD_WORD_FIRST_CHARS.has(lowerToken[0])) return false;
    return BAD_WORD_SET.has(lowerToken);
}

function isEditDistanceAtMostOne(a: string, b: string): boolean {
    if (a === b) return true;
    const alen = a.length;
    const blen = b.length;
    if (Math.abs(alen - blen) > 1) return false;

    if (alen === blen) {
        let mismatch = -1;
        for (let i = 0; i < alen; i += 1) {
            if (a[i] === b[i]) continue;
            if (mismatch !== -1) {
                return i === mismatch + 1
                    && a[mismatch] === b[i]
                    && a[i] === b[mismatch]
                    && a.slice(i + 1) === b.slice(i + 1);
            }
            mismatch = i;
        }
        return mismatch !== -1;
    }

    const longer = alen > blen ? a : b;
    const shorter = alen > blen ? b : a;
    let i = 0;
    let j = 0;
    let skipped = false;
    while (i < longer.length && j < shorter.length) {
        if (longer[i] === shorter[j]) {
            i += 1;
            j += 1;
            continue;
        }
        if (skipped) return false;
        skipped = true;
        i += 1;
    }
    return true;
}

function isLikelySevereVariant(lowerToken: string): boolean {
    if (lowerToken.length < 4) return false;
    if (!SEVERE_FIRST_CHARS.has(lowerToken[0])) return false;

    const severeConfusableMap: Record<string, string> = {
        "0": "o",
        "1": "i",
        "2": "z",
        "3": "e",
        "4": "a",
        "5": "s",
        "6": "g",
        "7": "t",
        "8": "b",
        "9": "g",
        "@": "a",
        "$": "s",
        "!": "i",
        "+": "t",
        "|": "i",
        "l": "i",
    };
    const normalizedSevereToken = lowerToken
        .split("")
        .map((ch) => severeConfusableMap[ch] ?? ch)
        .join("");

    const severeCandidates = new Set<string>([
        lowerToken,
        normalizedSevereToken,
    ]);

    for (const candidate of severeCandidates) {
        for (const base of SEVERE_BASE_WORDS) {
            if (Math.abs(base.length - candidate.length) > 1) continue;
            if (isEditDistanceAtMostOne(candidate, base)) return true;
        }
    }
    return false;
}

const MIN_CONCATENATED_LENGTH = 8;

function hasConcatenatedBadWords(normalized: string): boolean {
    if (normalized.length < MIN_CONCATENATED_LENGTH) return false;
    
    const commonBadWords = ["fuck", "shit", "bitch", "cunt", "whore", "damn", "pussy"];
    const matches: Array<{word: string; start: number; end: number}> = [];
    
    for (const word of commonBadWords) {
        let searchStart = 0;
        while (searchStart < normalized.length) {
            const idx = normalized.indexOf(word, searchStart);
            if (idx === -1) break;
            
            const newStart = idx;
            const newEnd = idx + word.length;
            const overlapsExisting = matches.some(
                (m) => newStart < m.end && newEnd > m.start
            );
            
            if (!overlapsExisting) {
                matches.push({word, start: newStart, end: newEnd});
            }
            
            searchStart = idx + 1;
        }
    }
    
    return matches.length >= 2;
}

function segmentHasBadWord(segment: string): boolean {
    const normalized = normalizeObfuscatedSegment(segment);
    if (isBadWordToken(normalized) || isLikelySevereVariant(normalized)) return true;

    // Check for Chinese slurs
    for (const [chineseSlur, englishEquiv] of Object.entries(CHINESE_SLUR_MAP)) {
        if (segment.includes(chineseSlur)) return true;
        // Also check the normalized version in case it's mixed with other chars
        if (normalized.includes(englishEquiv)) return true;
    }

    // Check for reversed/backwards text
    const reversed = normalized.split("").reverse().join("");
    if (isBadWordToken(reversed) || isLikelySevereVariant(reversed)) return true;

    // Check for multiple concatenated bad words (e.g., "fuckyoubitch")
    if (hasConcatenatedBadWords(normalized)) return true;

    // Catch obfuscated/concatenated severe slurs in long tokens.
    // We require at least 2 extra chars around the root to avoid common-word false positives.
    for (const severe of SEVERE_SUBSTRING_ROOTS) {
        const idx = normalized.indexOf(severe);
        if (idx === -1) continue;
        if (normalized.length - severe.length >= 2) return true;
    }

    const usernameCandidate = segment.replace(/^[^A-Za-z0-9_]+|[^A-Za-z0-9_]+$/g, "");
    if (!/^[A-Za-z0-9_]{3,20}$/.test(usernameCandidate)) return false;

    const normalizedCandidate = normalizeObfuscatedSegment(usernameCandidate);
    if (normalizedCandidate.length < 4) return false;

    for (const severe of SEVERE_SUBSTRING_ROOTS) {
        if (normalizedCandidate.includes(severe)) return true;
    }

    return false;
}

type TextSegment = {
    start: number;
    end: number;
    raw: string;
    normalized: string;
};

function collectNonWhitespaceSegments(text: string): TextSegment[] {
    const segments: TextSegment[] = [];
    const length = text.length;
    let i = 0;

    while (i < length) {
        if (/\s/.test(text[i])) {
            i += 1;
            continue;
        }

        const start = i;
        i += 1;
        while (i < length && !/\s/.test(text[i])) i += 1;
        const end = i;
        const raw = text.slice(start, end);
        segments.push({
            start,
            end,
            raw,
            normalized: normalizeObfuscatedSegment(raw),
        });
    }

    return segments;
}

function findCensorSpans(text: string): Array<{ start: number; end: number }> {
    const segments = collectNonWhitespaceSegments(text);
    const spans: Array<{ start: number; end: number }> = [];

    const maxJoinSegments = 4;
    let i = 0;
    while (i < segments.length) {
        let bestMatchEndIndex = -1;

        let combined = segments[i].normalized;
        if (isBadWordToken(combined) || segmentHasBadWord(segments[i].raw)) {
            bestMatchEndIndex = i;
        }

        const allowJoinedObfuscation = segments[i].normalized.length <= 2;
        if (allowJoinedObfuscation) {
            for (let j = i + 1; j < segments.length && j < i + maxJoinSegments; j += 1) {
                combined += segments[j].normalized;
                if (combined.length > 48) break;
                if (isBadWordToken(combined)) bestMatchEndIndex = j;
            }
        }

        if (bestMatchEndIndex >= i) {
            spans.push({
                start: segments[i].start,
                end: segments[bestMatchEndIndex].end,
            });
            i = bestMatchEndIndex + 1;
            continue;
        }

        i += 1;
    }

    return spans;
}

function readFromCache(input: string): string | undefined {
    const cached = censorCache.get(input);
    if (cached === undefined) return undefined;
    censorCache.delete(input);
    censorCache.set(input, cached);
    return cached;
}

function writeToCache(input: string, output: string): void {
    if (censorCache.size >= CENSOR_CACHE_LIMIT) {
        const oldestKey = censorCache.keys().next().value as string | undefined;
        if (oldestKey !== undefined) censorCache.delete(oldestKey);
    }
    censorCache.set(input, output);
}

export function getBadWords(): string[] {
    return [...normalizedBadWords];
}

export async function addBadWord(word: string): Promise<boolean> {
    const normalized = normalizeWordForStorage(word);
    if (!normalized) return false;
    if (BAD_WORD_SET.has(normalized)) return false;

    const next = [...normalizedBadWords, normalized];
    rebuildLookup(next);
    await persistBadWordsFile(normalizedBadWords);
    return true;
}

export async function removeBadWord(word: string): Promise<boolean> {
    const normalized = normalizeWordForStorage(word);
    if (!normalized) return false;
    if (!BAD_WORD_SET.has(normalized)) return false;

    const next = normalizedBadWords.filter((entry) => entry !== normalized);
    rebuildLookup(next);
    await persistBadWordsFile(normalizedBadWords);
    return true;
}

export function censorBadWords(text: string): string {
    if (typeof text !== "string" || text.length === 0) return text;

    const cached = readFromCache(text);
    if (cached !== undefined) return cached;

    const spans = findCensorSpans(text);
    if (spans.length === 0) {
        writeToCache(text, text);
        return text;
    }

    const chars = text.split("");
    for (const span of spans) {
        let seenFirstWordChar = false;
        for (let i = span.start; i < span.end; i += 1) {
            if (!isWordLikeCharacter(chars[i])) continue;
            if (!seenFirstWordChar) {
                seenFirstWordChar = true;
                continue;
            }
            chars[i] = "*";
        }
    }

    const censored = chars.join("");
    writeToCache(text, censored);
    return censored;
}

export function hasBadWords(text: string): boolean {
    if (typeof text !== "string" || text.length === 0) return false;
    return findCensorSpans(text).length > 0;
}
